# Iterative Loop

开发机器学习算法的迭代通常类似下图，首先需要设计模型的架构，然后训练模型，对模型进行一系列评估，再根据评估结果，继续设计模型，进入下一轮迭代。

![image-20230725163402194](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230725163402194.png)



## Example: Classify Spam Email

以垃圾邮件分类为例，可以将该任务视为一个文本分类任务，也是一个监督学习任务。

![image-20230725164652817](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230725164652817.png)

features可以是邮件中的某些词汇出现的次数。假设经过训练后，模型并没有设想的效果，且有以下几种优化方案可以参考：

- 获取更多垃圾邮件。例如构建一个项目，可以主动地订阅垃圾邮件来收集数据
- 设计更好的特征，例如引入路由转发信息
- 引入语义分析，使得算法能够将某些类似含义的词句归类
- 引入错拼检测，因为垃圾邮件经常会使用拼写错误的词句

结合之前的讨论可知，合适的选择能够有效节省开发时间，例如对于high bias问题，即使增加数据，也无法提升模型表现。



# Error Analysis

Error Analysis是指，在算法表现不好时，手动检查并分析算法出错的样例，并根据分析结果决定如何改进算法。

例如，在垃圾邮件的例子中，假设有100封邮件被分类错误，可以检查这100封邮件，按照邮件的特征进行分类：

- 卖药品的邮件，假设有21封
- 故意拼写错误的邮件，3封
- 不常见的路由转发，7封
- 盗取密码，18封
- 嵌入图片避开文本检查器的邮件，5封

这些例子并不是互斥的，同一个邮件可能存在多个特征；经过分析发现，在给出的假设例子中，卖药品和盗取密码的垃圾邮件占据了分类错误中的较多数，因此在改进算法时，可以优先考虑从这两个方向入手。例如增加某些特定药品的特征，或者检查文本中是否存在危险URL。

在实际的场景中，错例的数量可能远超100个，这种时候可以衡量错例数量与人力物力，用抽样的方法进行分析。



# Adding Data

传统的人工智能算法设计更多关注如何设计更好的算法，在有些情况下，关注如何设计更好的数据，可能会进一步提升这些算法的性能。

有些时候，相较于广泛的收集更多数据，**增加特定种类的数据**可能能够更有效地提升模型性能。例如在垃圾邮件的例子中，如果模型对卖药品的邮件或者含有钓鱼URL的邮件辨别能力不强，可以着重增加该类型的邮件，提升模型对这些类别邮件的筛选能力。



**Data Augmentation（数据增强）**通常适用于图像数据或者音频数据，通过对已有数据做出一些修改来获得新的数据，例如旋转、缩放图像，调整对比度或者做裁剪混合、模糊等。通过这种手段，可以获得label相同的新的样例。下图是通过使用网格进行随机扭曲增强数据的例子：

![image-20230725173433795](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230725173433795.png)

类似的，在音频样例中，可以通过引入其他噪音的方式来获取更多数据。

> 增强的手法应该集中在**数据本来就有的噪声**上，例如对树枝上的苹果的数据集，引入不同的明暗度，因为照片本身就可能在不同的阳光条件下拍摄；再比如在音频识别的例子里，引入嘈杂的背景音。



**Data Synthesis**技术不是修改现有的数据，而是从零开始重新创建数据，例如在Photo OCR（Photo Optical Character recognition）



# Transfer learning

假设想要识别0-9的手写数据，但目前没有足够的数据来完成这个任务，而且你发现了一个非常大的公共数据集，包含1000种常见的物体类别，1,000,000个样例。迁移学习执行以下操作

1. 在大数据集上训练一个模型，获得一系列的参数设置。
2. 将隐层参数拷贝到识别手写体的模型上，新的模型只有输出层和上一个模型不同。在小数据集上进行训练。
   - 一种方式是只训练新的输出层参数，如果数据集真的非常小，采用这种方法会比较好
   - 另一种方法是重新训练所有的参数，稍大一点的数据集可以采用这种方法



迁移学习的思想是首先在大的数据集上进行预训练，再在自己的小数据集上进行微调（fine-tune）。

预训练的模型不一定需要自己去实现，可以应用其他人已经预训练好的，更换输出层为自己需要的就可以。



理解迁移学习的有效性，可以参考此前提到的一个例子，如下图所示，在不同深度的隐层中，神经网络检测的特征等级不同。

![image-20230726141411748](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230726141411748.png)

这些低层级的特征可能在其他机器学习任务中能够通用，因此可以进行迁移。





# Full cycle of a machine learning project

在机器学习任务中，训练一个神经网路可能不是任务的全部，以语音识别的任务为例：

1. 评估项目。语音识别的目标就是可以通过语音输入文字
2. 收集数据。获取足够的语音-文本数据
3. 训练模型。训练，迭代改进，有时可能还需要回到上一步收集更多的数据。
4. 投入使用。部署、监控、维护整个系统的运行。可能需要返回上两步去优化模型。

![image-20230726142303674](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230726142303674.png)



常见的部署环境是服务器（inference server），用于与客户端交互。可能需要的一些软件工程（MLOps, Machine Learning Operations）：

- 根据使用人数的不同，设计软件确保可靠性和预测效率
- 管理用户
- 日志
- 系统监控
- 模型改进



# Guidelines of ethical system

- 在多元化群体中（diverse team）讨论，防止出现道德伦理问题
- 搜索特定行业的行业标准或者指导手册
- 添加审查系统（audit system），衡量是否存在问题
- 制定缓解方案（mitigation plan），例如在出现问题后回滚，在真的出现问题的时候可以快速反应。



# Error metrics for skewed datasets

如果某个数据集中正例和反例的数量相差太多，这种情况下error不适合作为评估的标准。

举例来说，假设要实现罕见病的二分类任务，该疾病的医学统计患病率为$0.5\%$，比较以下几个模型

- $y = 0$，$error = 0.5\%$
- $error = 1\%$的算法
- $error = 1.2\%$的算法

虽然第一种算法的error最低，但很明显直接假设所有人都不会患病，是非常不合理的。可以看出，在这种情况下，通常的**分类错误（classification error，或称错误率）**不适合用来作为评估标准。更常见的度量值为`Precision/Recall`，即**查准率/召回率**。



通过画矩阵的方法进行分析，如图所示，当预测结果与真值相同的时候，命名为`True`，反之为`False`，预测结果为真时标记`Positive`，反之为`Negative`。

![image-20230726152123656](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230726152123656.png)

**查准率（Precision）**代表在所有预测结果为`Positive`的样例中，值为`True`的样例，即
$$
P = \frac {TP}{TP + FP} = 75\%
$$

> 查准率反映了检测的精度

**召回率（Recall）**代表在所有值为`True`样例中，预测结果为`Positive`的样例，即
$$
R = \frac {TP}{TP + FN} = 60\%
$$

> 召回率反映了检测是否能够检测到真值

回到上面的例子，尽管$y = 0$这个不合理的方式具有最低的错误率$0.5\%$，但由于`Positive`永远为0，`TP`也为0，因此R永远是0（不用P是因为此时P的分母也为0，没意义）

如果一个学习算法的$P或R = 0$，则该学习算法不可用。通常我们希望查准率和召回率都足够高。



# Trade-off between P & R

如果一个算法具有高P值，意味着当算法预测结果为`Positive`的时候，患者更可能患有该疾病。

如果一个算法具有高R值，意味着当患者患病的时候，算法更可能检测出该疾病。

不幸的是，在实践中，通常需要对两者进行权衡。

假设使用logistic regression，考虑下面两种情况：

- 疾病的治疗成本非常高（例如高伤害、痛苦或者价格昂贵），但保守治疗不会带来太过于严重的后果
- 疾病的治疗成本相对可接受，但不治疗会带来严重的后归国



对第一种情况，我们可能希望检查结果更加准确，即提升查准率，此时可以将分类阈值提高（例如$0.5 \to 0.7$），使得模型在更加有把握的情况下才会输出1。与之相对的，由于TP会变小，召回率会随着下降。

而对第二种情况，我们可能更希望避免漏掉太多患病的患者，即提升召回率，此时可以将分类阈值降低（例如$0.5\to0.3$，使得模型能够检测出更多患者。相对的，由于FP变多，精确度会有所下降。



下图显示了`Recall / Precision`曲线，显示了在不同阈值下两者的关系，通常可以选择上面的某个点来确定需要的查准率和召回率（也可以在某些模型比对中看到，如果一个模型的曲线完全“包住"另一个模型的曲线，则可以认为这个模型的性能要更高）

![image-20230726163507530](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230726163507530.png)



虽然可以通过P-R图中的相对位置关系来比较模型的优劣，但对于类似下图中A, B曲线存在交叉的情况，很难估计两者的优劣，一种思路是比较P-R曲线包围的面积，但由于这个值不好估算，有时会采取其他度量标准，**综合评估P和R值**。例如：

![image-20230726164117566](D:\CS\Machine Learning\Course_2_Advanced Algorithm\7-Iterative Loop of ML Development.assets\image-20230726164117566.png)

- 平衡点（Break-Event Point, BEP），即$P = R$时的取值，图中$BEP_{A} > BEP_{B}$，认为A的性能优于B

- F1。P和R的调和平均数（harmonic mean），定义为
  $$
  \frac 1 {F_1} = \frac 1 2 (\frac 1 P + \frac 1 R)
  $$

  > 之所以用调和平均而不是用单纯的$\frac {P + R} 2$取平均，是因为通常的mean会受到极端值的影响，例如前面提到的$y = 0$或者$y = 1$这种极端例子，在$y =1$的情况下，召回率为1，而查准率却非常低，但二者的平均值却是0.5，如果单纯使用mean来评估的话，很可能会认为这是一个还不错的模型。
  >
  > 而如果采用调和平均，由于P和R都是概率，取值为[0, 1]，概率越小，则取倒数越大，得到的平均值也越大，意味着F1会更小，调和平均放大了极端小值的存在，能够更好地衡量P和R的均衡性。我们通常希望获得P和R都表现的比较好的模型，F1表现好的模型正符合这一需要
  >
  > 当存在$m$个值的时候，调和平均数的表达式为
  > $$
  > HM = \frac m {\sum_{i = 1}^M(\frac 1 x_i)}
  > $$
  > 

  西瓜书上给出了上面的公式的进一步推导
  $$
  F_1 = \frac { 2 \times P \times R}{P + R} = \frac {2TP} {2TP + FP + FN}
  $$
  由于TP和TN往往更好得到，上式也可以整理为
  $$
  F_1 = \frac {2TP} {TP + 样例总数 - TN}
  $$

- 调和平均对P和R的重视度相同，正如上面讨论过的，在特定应用中，有时会更重视P或R中的某一个，此时可以使用$F_{\beta}$度量
  $$
  \frac 1 {F_{\beta}} = \frac 1 {1 + \beta^2} \frac 1 P + \frac {\beta^2} {1 + \beta^2} \frac 1 R\\
  F_{\beta} = \frac {(1 + \beta^2)PR}{(\beta^2 + P) + R}
  $$
  $\beta > 0$反映了R相对于P的重要程度，当$\beta = 1$时2，退化为F1；当$\beta > 1$时，R影响更大；当$\beta < 1$时，P影响更大。

  > 因为$\beta < 1$时，$\frac 1 {1 + \beta^2} > \frac {\beta^2} {1 + \beta^2}$，此时$\frac 1 P$权重更高，因此$P$影响更大，反之则$R$影响更大。



# 参考

- 吴恩达《机器学习2022》
- 西瓜书
- 南瓜书

