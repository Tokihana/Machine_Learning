# AutoEncoder

自编码器（autoencoder）是神经网络的一种，能够将输入编码后，再解码成同样的输出

自编码器的损失函数可以描述为
$$
L(X,decoder(encoder(X)))
$$


## undercomplete AE

若编码维度小于解码维度，则称为欠完备（undercomplete）自编码器，这类自编码器能够降维数据，捕捉最重要的特征；

若解码器是线性的，且L使用均方误差，则欠完备编码器会产生和PCA相同的子空间。

**自编码器应该使用适当的大小**，否则可能无法学习到任何有用的信息。





# generator

调整generator，将label部分改为返回train

```py
# 定义sequence
class HDF5DataGenerator(Sequence):
    def __init__(self, hdf5_file, batch_size, shuffle=True, autoencoder = False):
        self.hdf5_file = h5py.File(hdf5_file, 'r')
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.autoencoder = autoencoder
        self.indexes = np.arange(len(self.hdf5_file['data']))
        if self.shuffle:
            np.random.shuffle(self.indexes) # 这里打乱index而不是打乱data，应该是因为h5要求index必须升序的原因
            
    def __len__(self):
        # 这里的__len__实际返回的是chunk个数
        return int(np.ceil(len(self.hdf5_file['data']) / float(self.batch_size))) - 4
    
    def __getitem__(self, index):
        indexes = self.indexes[index*self.batch_size:
                               min(len(self.hdf5_file['data']), (index+1)*self.batch_size)]
        batch_data = np.array(self.hdf5_file['data'][indexes])
        if self.autoencoder:
            batch_labels = batch_data
            return batch_data, batch_labels
        else:
            batch_labels = np.array(self.hdf5_file['label'][indexes])
            return batch_data, batch_labels
    
    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)
```



# 网络架构与训练

首先跑单个数据，看看能不能逼近0，并测试latent_dim

层数固定使用三层，尝试[128, 256,512,1024]个node

```py
latent_dim = 128

class Autoencoder(Model):
    def __init__(self, latent_dim, io_dim):
        super(Autoencoder, self).__init__()
        self.latent_dim = latent_dim
        self.io_dim = io_dim
        self.encoder = tf.keras.Sequential([
            Dense(latent_dim, activation='relu', input_shape=[io_dim,]),
            Dense(latent_dim, activation='relu'),
            Dense(latent_dim, activation='relu'),
        ])
        self.decoder = tf.keras.Sequential([
            Dense(latent_dim, activation='relu', input_shape=[latent_dim,]),
            Dense(latent_dim, activation='relu'),
            Dense(latent_dim, activation='relu'),
            Dense(io_dim, activation='linear'),
        ])

    def call(self, x):
        return self.decoder(self.encoder(x))

autoencoder = Autoencoder(latent_dim, X.shape[1])
```

```py
autoencoder.compile(optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001,
                                                          beta_1=0.9,
                                                          beta_2=0.999,
                                                          epsilon=1e-08,),
              loss = 'mse', metrics=['mae'],)
```

```py
history = autoencoder.fit(generator,
                epochs=100,
                shuffle=True,
                workers = 2, # 并行处理的并发数
                use_multiprocessing=True,
               validation_data=(X_val, X_val))
```

![image-20230830174329077](D:\CS\Machine Learning\Projects\AI4Science\5-自编码器.assets\image-20230830174329077.png)



## 保存history

```py
import pickle
with open('history.pkl', 'wb') as f:
    pickle.dump(history.history, f)
```



## 保存模型

因为autoencoder是自定义的模型类，因此需要编写序列化方法才能保存模型

需要实现以下两个方法

Specifications:

- `get_config()` should return a JSON-serializable dictionary in order to be compatible with the Keras architecture- and model-saving APIs.
- `from_config(config)` (a `classmethod`) should return a new layer or model object that is created from the config. The default implementation returns `cls(**config)`.

```py
latent_dim = 128
@keras.saving.register_keras_serializable(package="ComplexModels")
class Autoencoder(Model):
    ...
    # get_config用于保存自定义模型
    # update中需要写入参数字典
    def get_config(self):
        config = super().get_config()
        config.update(
            {
                "latent_dim": self.latent_dim,
                "io_dim": self.io_dim,
            }
        )
        return config
    
    # from_config方法不是必须重载的，因为自编码器实现使用的都是
    # 整形、字符串和tf.keras内置的对象
    @classmethod
    def from_config(cls, config):
        # Note that you can also use `keras.saving.deserialize_keras_object` here
        config["latent_dim"] = tf.keras.layers.deserialize(config["latent_dim"])
        config["io_dim"] = tf.keras.layers.deserialize(config["io_dim"])
        return cls(**config)
```



### 修正 - 保存为tf格式就可以，不需要重载config方法

只需要将模型保存为tf格式

```py
autoencoder.save('AE_Class', save_format='tf')
```

然后再读取

```py
autoencoder = tf.keras.models.load_model('AE_Class')
```

就可以了



## 测试

按照下面的流程测试不同的node数

1. 使用generator抽取一部分1024条作为验证集
2. 修改generator的`__len__()`方法，使得`fit()`不会访问到验证集
3. 用不同的node数训练AE
4. 用训练好的AE编码特征，得到P、T集并保存为CSV文件

| 特征数 | node数 | 编码mae | 模型训练mae |
| ------ | ------ | ------- | ----------- |
| 485512 | 128    | 0.42    | 17.80       |



效果不是很好，可能还是得先跑一轮特征筛选。

先用FDR0.2 + MI0.7筛到18W左右，再跑AE

| 特征数 | node 数 | 编码mae | 模型训练mae |
| ------ | ------- | ------- | ----------- |
| 187035 | 128     | 0.26571 | 7.0233      |



效果还是很差，我估计需要进一步压特征

从MI图像上来看，将阈值设到0.7可能也没问题

![image-20230901152654984](D:\CS\Machine Learning\Projects\AI4Science\5-自编码器.assets\image-20230901152654984.png)

先用互信>0.7将特征压到2W个左右，然后将node数提升到1024

感觉有戏，编码mae降了一个数量级

| 特征数 | node 数 | 编码mae | 模型训练mae |
| ------ | ------- | ------- | ----------- |
| 25388  | 1024    | 0.02788 | 8.3336      |



看来是思路不太对

我想想，现在的encoder架构收集的应该是恢复层所需要的信息，即可能损失age相关的信息？





# 思路整理

目前的方案

1. 使用filter方法选择特征（第一次降维）
2. 使用encoder编码
3. 用编码后的数据进行训练？

核心问题还是encoder，编码error会直接影响训练效果，目前想不到优化encoder的方向



另一种方案

1. 选择特征
2. fea_imp二次选择（考虑循环选择？）
3. 二次选择的数据进行训练
