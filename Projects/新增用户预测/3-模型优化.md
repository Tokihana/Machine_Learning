

# 特征scale

有些特征值域太大，做一下scale

```py
from sklearn.preprocessing import scale 
train_data = scale(train_data[train_data.columns.drop(['udmap', 'common_ts', 'uuid'])])
test_data = scale(test_data[test_data.columns.drop(['udmap', 'common_ts', 'uuid'])])
```



# 根据树模型进行特征选择

绘制特征图像

```py
import matplotlib.pyplot as plt
plt.hist(fea_imp/fea_imp.max(),  np.linspace(0, 1, 100))
```

![image-20230823194202790](D:\CS\Machine Learning\Projects\新增用户预测\3-模型优化.assets\image-20230823194202790.png)

取`0.005`的阈值试一试，效果有些提升

```py
sel = fea_imp > 0.005
skf = StratifiedKFold(n_splits = 10)
X = train_data.drop(['udmap', 'common_ts', 'uuid', 'target'], axis=1).iloc[:,sel]
y = train_data['target']
preds = np.zeros((test_data.shape[0]))
total_score = 0
for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):
    X_train, X_val, y_train, y_val = X.iloc[train_idx], X.iloc[val_idx], y.iloc[train_idx], y.iloc[val_idx]
    clf = CatBoostClassifier(iterations = 30000, **params,)
    clf.fit(X_train, y_train, 
            eval_set=(X_val, y_val), 
            use_best_model=True,
            metric_period = 500)
    
    total_score += f1_score(y_val, clf.predict(X_val)) / 10  

    test_pred = clf.predict(test_data.drop(['udmap', 'common_ts', 'uuid'], axis = 1).iloc[:,sel])
    preds+=test_pred/10
print(f'Total f1 score: {total_score}')
```



